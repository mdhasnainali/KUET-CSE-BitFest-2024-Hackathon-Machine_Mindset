{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.19169329073482427,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003194888178913738,
      "grad_norm": 0.9322354793548584,
      "learning_rate": 4e-05,
      "loss": 2.3487,
      "step": 1
    },
    {
      "epoch": 0.006389776357827476,
      "grad_norm": 0.9547149538993835,
      "learning_rate": 8e-05,
      "loss": 2.3354,
      "step": 2
    },
    {
      "epoch": 0.009584664536741214,
      "grad_norm": 1.0887272357940674,
      "learning_rate": 0.00012,
      "loss": 2.3756,
      "step": 3
    },
    {
      "epoch": 0.012779552715654952,
      "grad_norm": 1.1193065643310547,
      "learning_rate": 0.00016,
      "loss": 2.2313,
      "step": 4
    },
    {
      "epoch": 0.01597444089456869,
      "grad_norm": 1.169347882270813,
      "learning_rate": 0.0002,
      "loss": 2.093,
      "step": 5
    },
    {
      "epoch": 0.019169329073482427,
      "grad_norm": 1.0167250633239746,
      "learning_rate": 0.00019636363636363636,
      "loss": 1.8074,
      "step": 6
    },
    {
      "epoch": 0.022364217252396165,
      "grad_norm": 0.863689124584198,
      "learning_rate": 0.00019272727272727274,
      "loss": 1.554,
      "step": 7
    },
    {
      "epoch": 0.025559105431309903,
      "grad_norm": 1.2676531076431274,
      "learning_rate": 0.0001890909090909091,
      "loss": 1.2824,
      "step": 8
    },
    {
      "epoch": 0.02875399361022364,
      "grad_norm": 1.1466468572616577,
      "learning_rate": 0.00018545454545454545,
      "loss": 1.0989,
      "step": 9
    },
    {
      "epoch": 0.03194888178913738,
      "grad_norm": 0.7900161147117615,
      "learning_rate": 0.00018181818181818183,
      "loss": 0.9947,
      "step": 10
    },
    {
      "epoch": 0.03514376996805112,
      "grad_norm": 0.717451274394989,
      "learning_rate": 0.0001781818181818182,
      "loss": 0.8465,
      "step": 11
    },
    {
      "epoch": 0.038338658146964855,
      "grad_norm": 0.5392537713050842,
      "learning_rate": 0.00017454545454545454,
      "loss": 0.8784,
      "step": 12
    },
    {
      "epoch": 0.04153354632587859,
      "grad_norm": 0.5269109606742859,
      "learning_rate": 0.0001709090909090909,
      "loss": 0.7712,
      "step": 13
    },
    {
      "epoch": 0.04472843450479233,
      "grad_norm": 0.4417952001094818,
      "learning_rate": 0.00016727272727272728,
      "loss": 0.8592,
      "step": 14
    },
    {
      "epoch": 0.04792332268370607,
      "grad_norm": 0.380805104970932,
      "learning_rate": 0.00016363636363636366,
      "loss": 0.7356,
      "step": 15
    },
    {
      "epoch": 0.051118210862619806,
      "grad_norm": 0.41234466433525085,
      "learning_rate": 0.00016,
      "loss": 0.7628,
      "step": 16
    },
    {
      "epoch": 0.054313099041533544,
      "grad_norm": 0.4127505123615265,
      "learning_rate": 0.00015636363636363637,
      "loss": 0.6352,
      "step": 17
    },
    {
      "epoch": 0.05750798722044728,
      "grad_norm": 0.4276754558086395,
      "learning_rate": 0.00015272727272727275,
      "loss": 0.6972,
      "step": 18
    },
    {
      "epoch": 0.06070287539936102,
      "grad_norm": 0.44446542859077454,
      "learning_rate": 0.0001490909090909091,
      "loss": 0.7526,
      "step": 19
    },
    {
      "epoch": 0.06389776357827476,
      "grad_norm": 0.46728941798210144,
      "learning_rate": 0.00014545454545454546,
      "loss": 0.6895,
      "step": 20
    },
    {
      "epoch": 0.0670926517571885,
      "grad_norm": 0.5143897533416748,
      "learning_rate": 0.00014181818181818184,
      "loss": 0.6389,
      "step": 21
    },
    {
      "epoch": 0.07028753993610223,
      "grad_norm": 0.4265654981136322,
      "learning_rate": 0.0001381818181818182,
      "loss": 0.67,
      "step": 22
    },
    {
      "epoch": 0.07348242811501597,
      "grad_norm": 0.4722287952899933,
      "learning_rate": 0.00013454545454545455,
      "loss": 0.727,
      "step": 23
    },
    {
      "epoch": 0.07667731629392971,
      "grad_norm": 0.5182834267616272,
      "learning_rate": 0.00013090909090909093,
      "loss": 0.7476,
      "step": 24
    },
    {
      "epoch": 0.07987220447284345,
      "grad_norm": 0.46002715826034546,
      "learning_rate": 0.00012727272727272728,
      "loss": 0.7299,
      "step": 25
    },
    {
      "epoch": 0.08306709265175719,
      "grad_norm": 0.5354167819023132,
      "learning_rate": 0.00012363636363636364,
      "loss": 0.6606,
      "step": 26
    },
    {
      "epoch": 0.08626198083067092,
      "grad_norm": 0.5449813604354858,
      "learning_rate": 0.00012,
      "loss": 0.6615,
      "step": 27
    },
    {
      "epoch": 0.08945686900958466,
      "grad_norm": 0.4955989718437195,
      "learning_rate": 0.00011636363636363636,
      "loss": 0.6446,
      "step": 28
    },
    {
      "epoch": 0.0926517571884984,
      "grad_norm": 0.5680204033851624,
      "learning_rate": 0.00011272727272727272,
      "loss": 0.5594,
      "step": 29
    },
    {
      "epoch": 0.09584664536741214,
      "grad_norm": 0.5882876515388489,
      "learning_rate": 0.00010909090909090909,
      "loss": 0.6517,
      "step": 30
    },
    {
      "epoch": 0.09904153354632587,
      "grad_norm": 0.5737284421920776,
      "learning_rate": 0.00010545454545454545,
      "loss": 0.6304,
      "step": 31
    },
    {
      "epoch": 0.10223642172523961,
      "grad_norm": 0.4880077540874481,
      "learning_rate": 0.00010181818181818181,
      "loss": 0.646,
      "step": 32
    },
    {
      "epoch": 0.10543130990415335,
      "grad_norm": 0.5229907631874084,
      "learning_rate": 9.818181818181818e-05,
      "loss": 0.6861,
      "step": 33
    },
    {
      "epoch": 0.10862619808306709,
      "grad_norm": 0.5195857286453247,
      "learning_rate": 9.454545454545455e-05,
      "loss": 0.666,
      "step": 34
    },
    {
      "epoch": 0.11182108626198083,
      "grad_norm": 0.5150617361068726,
      "learning_rate": 9.090909090909092e-05,
      "loss": 0.612,
      "step": 35
    },
    {
      "epoch": 0.11501597444089456,
      "grad_norm": 0.45084598660469055,
      "learning_rate": 8.727272727272727e-05,
      "loss": 0.6128,
      "step": 36
    },
    {
      "epoch": 0.1182108626198083,
      "grad_norm": 0.43794354796409607,
      "learning_rate": 8.363636363636364e-05,
      "loss": 0.526,
      "step": 37
    },
    {
      "epoch": 0.12140575079872204,
      "grad_norm": 0.41685548424720764,
      "learning_rate": 8e-05,
      "loss": 0.642,
      "step": 38
    },
    {
      "epoch": 0.12460063897763578,
      "grad_norm": 0.3816126883029938,
      "learning_rate": 7.636363636363637e-05,
      "loss": 0.5658,
      "step": 39
    },
    {
      "epoch": 0.12779552715654952,
      "grad_norm": 0.36637958884239197,
      "learning_rate": 7.272727272727273e-05,
      "loss": 0.6378,
      "step": 40
    },
    {
      "epoch": 0.13099041533546327,
      "grad_norm": 0.34646573662757874,
      "learning_rate": 6.90909090909091e-05,
      "loss": 0.5391,
      "step": 41
    },
    {
      "epoch": 0.134185303514377,
      "grad_norm": 0.3910582661628723,
      "learning_rate": 6.545454545454546e-05,
      "loss": 0.6274,
      "step": 42
    },
    {
      "epoch": 0.13738019169329074,
      "grad_norm": 0.3812166452407837,
      "learning_rate": 6.181818181818182e-05,
      "loss": 0.6929,
      "step": 43
    },
    {
      "epoch": 0.14057507987220447,
      "grad_norm": 0.36039817333221436,
      "learning_rate": 5.818181818181818e-05,
      "loss": 0.6748,
      "step": 44
    },
    {
      "epoch": 0.14376996805111822,
      "grad_norm": 0.38109955191612244,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 0.5125,
      "step": 45
    },
    {
      "epoch": 0.14696485623003194,
      "grad_norm": 0.38847580552101135,
      "learning_rate": 5.090909090909091e-05,
      "loss": 0.5609,
      "step": 46
    },
    {
      "epoch": 0.1501597444089457,
      "grad_norm": 0.375364750623703,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 0.6202,
      "step": 47
    },
    {
      "epoch": 0.15335463258785942,
      "grad_norm": 0.3836655020713806,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 0.5793,
      "step": 48
    },
    {
      "epoch": 0.15654952076677317,
      "grad_norm": 0.3591923117637634,
      "learning_rate": 4e-05,
      "loss": 0.6353,
      "step": 49
    },
    {
      "epoch": 0.1597444089456869,
      "grad_norm": 0.35311731696128845,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 0.4961,
      "step": 50
    },
    {
      "epoch": 0.16293929712460065,
      "grad_norm": 0.36580267548561096,
      "learning_rate": 3.272727272727273e-05,
      "loss": 0.6048,
      "step": 51
    },
    {
      "epoch": 0.16613418530351437,
      "grad_norm": 0.4025091230869293,
      "learning_rate": 2.909090909090909e-05,
      "loss": 0.5415,
      "step": 52
    },
    {
      "epoch": 0.16932907348242812,
      "grad_norm": 0.4416026473045349,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 0.6329,
      "step": 53
    },
    {
      "epoch": 0.17252396166134185,
      "grad_norm": 0.34749525785446167,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 0.5472,
      "step": 54
    },
    {
      "epoch": 0.1757188498402556,
      "grad_norm": 0.4106122553348541,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.6441,
      "step": 55
    },
    {
      "epoch": 0.17891373801916932,
      "grad_norm": 0.37387239933013916,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 0.6142,
      "step": 56
    },
    {
      "epoch": 0.18210862619808307,
      "grad_norm": 0.3967682421207428,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.6195,
      "step": 57
    },
    {
      "epoch": 0.1853035143769968,
      "grad_norm": 0.38059547543525696,
      "learning_rate": 7.272727272727272e-06,
      "loss": 0.5882,
      "step": 58
    },
    {
      "epoch": 0.18849840255591055,
      "grad_norm": 0.4491741359233856,
      "learning_rate": 3.636363636363636e-06,
      "loss": 0.5677,
      "step": 59
    },
    {
      "epoch": 0.19169329073482427,
      "grad_norm": 0.44084668159484863,
      "learning_rate": 0.0,
      "loss": 0.6857,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6359473733664768.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
